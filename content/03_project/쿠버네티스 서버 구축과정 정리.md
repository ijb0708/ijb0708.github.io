
### 📌 1. 클러스터 구성 및 초기 설정

#### 🔹 사용 환경

- Proxmox 기반 VM 환경에서 Kubernetes 구성
    
- k3s 이용: 경량화된 K8s 배포판 (마스터 1개, 워커노드 1~2개, 스토리지 노드 1개)
    
- 내부망에서 운영되며, VPN 환경 내에서 마스터 노드로 접속
    

#### 🔹 설치 절차 및 주요 체크 사항

- `k3s` 설치 후 `kubectl` 설정 파일을 `/etc/rancher/k3s/k3s.yaml` 경로에서 확보
    
- 외부에서 Lens나 kubectl 클라이언트로 접근할 수 있도록 `server` 항목을 내부 IP로 수정
    
- 마스터 노드와 워커 노드 간 통신을 위한 포트 확인: 6443, 10250, 30000~32767 (NodePort)
    

#### 🔹 SSH 및 sudo 관리

- 마스터 노드에서만 `kubectl` 작업을 진행하며, sudo 필요 여부 판단 후 `~/.kube/config` 설정
    
- `$KUBECONFIG` 환경변수에 `/etc/rancher/k3s/k3s.yaml`를 설정해 지속적인 권한 유지
    

---

### 📌 2. Longhorn 스토리지 구성 및 노드 역할 분리

#### 🔹 Longhorn 설치 및 세팅

- Helm으로 `longhorn/longhorn` 차트 설치:
    
    ```
    helm install longhorn longhorn/longhorn \
      --namespace longhorn-system \
      --set defaultSettings.defaultDataPath="/mnt/longhorn-data1" \
      --set tolerations[0].key="node-role.kubernetes.io/storage" \
      --set tolerations[0].operator="Equal" \
      --set tolerations[0].value="true" \
      --set tolerations[0].effect="NoSchedule"
    ```
    
- `/mnt/longhorn-data1` 디렉토리를 마운트할 스토리지 디스크는 UUID 기준으로 `/etc/fstab`에 고정 등록
    

#### 🔹 iscsi 세팅

- Longhorn은 iSCSI를 통해 볼륨을 연결하므로 `open-iscsi` 패키지를 모든 관련 노드에 설치
    
- 설치 여부 확인 명령어:
    
    ```
    dpkg -l | grep open-iscsi
    systemctl status iscsid
    ```
    

#### 🔹 노드 구성 및 역할 구분

- 마스터 노드: `Node Scheduling = false`, `Disk Scheduling = false`
    
- 일반 워커 노드: 필요에 따라 스토리지 사용
    
- 스토리지 전용 노드: `Node Scheduling = true`, `Disk Scheduling = true`, `Eviction Requested = false`
    

#### 🔹 볼륨 설정 이해

- Replica는 Longhorn이 자동 분산 저장하며, 설정된 스토리지 노드들에 복제본을 배치함
    
- `diskTag`, `nodeSelector`, `eviction` 등으로 세밀한 제어 가능
    

---

### 📌 3. Kubernetes Dashboard 및 Lens 설정

#### 🔹 Kubernetes Dashboard 설치

- 공식 recommended.yaml로 설치:
    
    ```
    kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.7.0/aio/deploy/recommended.yaml
    ```
    
- admin-user 생성용 YAML 파일 작성 및 적용:
    
    ```
    apiVersion: v1
    kind: ServiceAccount
    metadata:
      name: admin-user
      namespace: kubernetes-dashboard
    ---
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRoleBinding
    metadata:
      name: admin-user-binding
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: ClusterRole
      name: cluster-admin
    subjects:
    - kind: ServiceAccount
      name: admin-user
      namespace: kubernetes-dashboard
    ```
    
- `kubectl port-forward` 또는 `NodePort`를 통해 외부 접근 가능하게 변경
    

#### 🔹 Lens 설정

- macOS에서는 `brew install --cask lens`로 설치
    
- kubeconfig 경로: `~/.kube/config`로 복사 및 수정
    
    ```
    scp user@master:/etc/rancher/k3s/k3s.yaml ~/.kube/config
    ```
    
- `server: https://127.0.0.1:6443` → 실제 마스터 노드 IP로 변경
    
- Lens 실행 후 자동으로 클러스터 연결됨
    

#### 🔹 Lens에서 확인할 수 있는 항목

- Nodes: CPU, 메모리, Schedulable 상태, 역할
    
- Workloads: Pod, Deployment, DaemonSet, StatefulSet
    
- Storage: PVC, PV, StorageClass, Snapshot
    
- Networking: Services, Ingress, Endpoints
    
- Custom Resources: longhorn.volumes 등
    

---

### 📌 4. 스토리지 가용성 및 마운트 관련 고려사항

#### 🔹 재부팅 시 주의사항

- `/etc/fstab`에 UUID로 마운트 등록되어 있어야 함
    
- Longhorn 볼륨 마운트 실패 시 PVC 상태가 `Pending`, Pod는 `CrashLoopBackOff` 가능
    
- IP가 변경되면 kubeconfig에서 server 주소가 일치해야 Lens/kubectl 접속 가능
    

#### 🔹 Eviction / Scheduling 제어

- `Eviction Requested: true` → 해당 노드에서 Replica 제거 후 다른 노드로 이동
    
- `Node Scheduling`, `Disk Scheduling` 모두 false → Replica 생성 안 함
    
- `schedulable` 옵션으로 스토리지 분산 여부 제어 가능
    

---

### 📌 5. 향후 계획 및 다음 단계

#### 🔹 Ingress 구성 예정

- 여러 서비스에 대해 포트 대신 도메인 기반 접근 구성
    
- Traefik(기본), 또는 nginx-ingress 설치 예정
    
- Ingress 리소스 YAML 작성 후 hosts 파일과 연동
    

#### 🔹 로깅/모니터링 도구 적용

- kube-ops-view: 실시간 노드/Pod 시각화
    
- stern: 로그 실시간 tail
    
- k9s: 터미널 기반 리소스 브라우징
    
- 이후 Grafana, Loki 도입 검토 가능

이전까지 진행사항

## ingress 진행

좋아, 그럼 지금부터 **Ingress 설정** 바로 들어가자.  
→ 이건 너가 만든 여러 서비스를 **도메인 또는 경로 기반으로 접근 가능하게 만드는 핵심 작업**이야. 🌐

---

좋은 질문이야!  
Traefik과 Nginx Ingress Controller는 둘 다 **쿠버네티스에서 Ingress(도메인 라우팅)를 처리하는 컨트롤러**인데,  
성격과 철학이 꽤 달라. 🔍

---

## ✅ 핵심 차이 요약

|항목|**Nginx Ingress**|**Traefik Ingress**|
|---|---|---|
|🧠 설정 방식|**Ingress 리소스 위주**|**Ingress + CRD(Custom Resource Definitions)**|
|📦 구성 방식|단순하고 전통적인 리버스 프록시|동적, 자동 탐지, 이벤트 기반|
|📊 시각화 대시보드|❌ 없음 (수동으로 연동 가능)|✅ 웹 UI 있음 (기본 제공)|
|🧰 커스터마이징|익숙한 nginx.conf 스타일|태그 기반 라우팅, 다양한 어노테이션|
|⚙️ 복잡한 라우팅|덜 유연 (단순 path/host)|매우 유연 (path, host, 헤더 기반 등)|
|🐣 배포 복잡도|매우 널리 쓰이고 문서 많음|약간 생소할 수 있지만 k3s 기본 탑재|
|⚡ 반응성|configmap 기반, 느릴 수 있음|이벤트 기반 → 빠르게 라우팅 갱신|
|🧩 TLS 연동|cert-manager와 수동 통합|Let's Encrypt 자동 통합 가능|

---

## ✅ 어떤 걸 선택하면 좋을까?

|너 상황|추천|
|---|---|
|⚡ 빠른 테스트, 간단한 설정|**Nginx**|
|🧠 이벤트 기반, 자동화 지향|**Traefik**|
|🔍 가시성 있는 운영, 대시보드|**Traefik**|
|📜 전통적인 nginx에 익숙|**Nginx**|
|💡 k3s 기본 구성 그대로 사용|**Traefik (이미 설치됨일 수도 있음)**|

---

## ✅ 참고: Traefik은 k3s 설치 시 **기본으로 같이 설치되는 경우가 많아**

확인해보자:

```bash
kubectl get pods -A | grep traefik
```

만약 이미 떠 있다면 굳이 nginx 설치 안 하고 Traefik 그대로 써도 돼.

---

## 🎯 결론

- 🔧 **간단한 path 기반 라우팅, 익숙한 nginx 스타일 → nginx-ingress**
    
- 🌐 **자동 탐지, 대시보드, 이벤트 기반 운영 → Traefik**
    

---

너가 앞으로 운영 쪽까지 확장할 생각이라면 Traefik도 꽤 매력적인 선택이야.  
한 번 써보면 “자동으로 다 돼버리는 느낌”이 좀 있어 😎

둘 중 하나 골라서 지금 바로 Ingress 구성 도와줄게 — 어떤 쪽이 당겨?

## ✅ 1. 현재 상태 확인

먼저 확인할 건 이거야:

|항목|설명|확인 방법|
|---|---|---|
|✅ Ingress Controller 설치 여부|Traefik or Nginx|`kubectl get pods -A|
|✅ ClusterIP or NodePort 설정 여부|외부에서 접근 가능한가?|`kubectl get svc -A|
|✅ 사용할 도메인|예: `app.local`, `dashboard.local`|`/etc/hosts` 수정 필요 (로컬 테스트용)|

---

## ✅ 2. Ingress Controller 설치 (nginx로 예시)

### 👉 nginx-ingress 설치 (Helm)

```bash
helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm repo update

helm install ingress-nginx ingress-nginx/ingress-nginx \
  --namespace ingress-nginx \
  --create-namespace
```

설치 후 확인:

```bash
kubectl get pods -n ingress-nginx
kubectl get svc -n ingress-nginx
```

NodePort가 열려 있는지 확인!

---

## ✅ 3. 서비스 하나 Ingress로 노출하기 (예: nginx-test)

먼저 테스트용 서비스 만들었을 거야:

```bash
kubectl create deployment nginx-test --image=nginx
kubectl expose deployment nginx-test --port=80 --type=ClusterIP
```

---

## ✅ 4. Ingress 리소스 생성

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: nginx-test-ingress
  namespace: default
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
    - host: nginx.local
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: nginx-test
                port:
                  number: 80
```

적용:

```bash
kubectl apply -f nginx-ingress.yaml
```

---

## ✅ 5. `/etc/hosts` 설정 (로컬에서 nginx.local로 접속 가능하게)

```plaintext
<Ingress Controller의 IP 또는 노드 IP>  nginx.local
```

예:

```plaintext
192.168.0.50  nginx.local
```

그 다음 브라우저에서 `http://nginx.local` 접속 → Nginx 페이지가 뜨면 성공 🎉

---

## ✅ 요약

|단계|설명|
|---|---|
|① Ingress Controller 설치|Traefik or nginx|
|② 서비스 생성|nginx-test 등|
|③ Ingress 리소스 생성|도메인 기반 접근 설정|
|④ `/etc/hosts` 수정|로컬 도메인 연결|

---

진입 확인 후, 다음엔 Dashboard나 Longhorn도 도메인으로 붙일 수 있어.

지금 Ingress Controller로 Traefik 쓸지 nginx 쓸지 정해졌어?  
또는 위 Helm 방식 바로 쓸까? 😎