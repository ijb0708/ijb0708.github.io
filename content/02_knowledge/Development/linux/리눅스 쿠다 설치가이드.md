---
tags:
  - linux
  - docker
  - cuda
  - podman
---

# 사용되는 환경 정보

- **운영체제**: 데비안 12
    
- **CUDA 버전**: 12.3
    
- **컨테이너 관리 도구**: Podman or docker
    

## 1. 사전 설치

먼저 필요한 패키지들을 설치합니다.

```bash
sudo apt install curl
sudo apt-get install python-software-properties
sudo apt-get install software-properties-common
```

## 2. NVIDIA Toolkit 설치

NVIDIA Container Toolkit을 설치하기 위해 필요한 명령어들입니다.

```bash
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \
  && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
```

```bash
sed -i -e '/experimental/ s/^#//g' /etc/apt/sources.list.d/nvidia-container-toolkit.list
```

```bash
sudo apt-get update
```

```bash
sudo apt-get install -y nvidia-container-toolkit
```

참고: [CUDA Toolkit Archive](https://developer.nvidia.com/cuda-toolkit-archive)

## 3. Podman 설치

Podman 및 Podman Compose를 설치합니다.

```bash
sudo apt install podman podman-compose
```

설치 확인:

```bash
podman version
```

 * 일반 도커사용시 도커 설치가능

## 4. CUDA 설치

### `add-apt-repository` 명령어 설치

CUDA 설치 전, `add-apt-repository` 명령어가 필요합니다.

```bash
sudo apt-get install python-software-properties
```

설치 명령어:

```bash
wget https://developer.download.nvidia.com/compute/cuda/12.3.0/local_installers/cuda-repo-debian12-12-3-local_12.3.0-545.23.06-1_amd64.debsudo 
```

```bash
dpkg -i cuda-repo-debian12-12-3-local_12.3.0-545.23.06-1_amd64.debsudo 
```

```bash
cp /var/cuda-repo-debian12-12-3-local/cuda-*-keyring.gpg /usr/share/keyrings/
```

```bash
sudo add-apt-repository contribsudo apt-get update
```

```bash
sudo apt-get -y install cuda-toolkit-12-3
```

```bash
sudo apt-get install -y cuda-drivers
```

### CUDA 드라이버 설치:

```bash
sudo apt-get install -y nvidia-kernel-open-dkms 
sudo apt-get install -y cuda-drivers
```

환경 변수 추가:

```shell
echo 'export PATH=/usr/local/cuda/bin${PATH:+:${PATH}}' >> ~/.bashrc
```

```shell
echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64' >> ~/.bashrc
```

## 5. cuDNN 설치

cuDNN을 설치하고 필요한 라이브러리를 복사합니다.

```bash
sudo cp include/cudnn* /usr/local/cuda/include 
sudo cp lib/libcudnn* /usr/local/cuda/lib64 
sudo chmod a+r /usr/local/cuda/include/cudnn.h /usr/local/cuda/lib64/libcudnn*

sudo ln -sf /usr/local/cuda/targets/x86_64-linux/lib/libcudnn_adv_train.so.8.9.2 /usr/local/cuda/targets/x86_64-linux/lib/libcudnn_adv_train.so.8 
sudo ln -sf /usr/local/cuda/targets/x86_64-linux/lib/libcudnn_ops_infer.so.8.9.2 /usr/local/cuda/targets/x86_64-linux/lib/libcudnn_ops_infer.so.8 
sudo ln -sf /usr/local/cuda/targets/x86_64-linux/lib/libcudnn_cnn_train.so.8.9.2 /usr/local/cuda/targets/x86_64-linux/lib/libcudnn_cnn_train.so.8 
sudo ln -sf /usr/local/cuda/targets/x86_64-linux/lib/libcudnn_adv_infer.so.8.9.2 /usr/local/cuda/targets/x86_64-linux/lib/libcudnn_adv_infer.so.8 
sudo ln -sf /usr/local/cuda/targets/x86_64-linux/lib/libcudnn_ops_train.so.8.9.2 /usr/local/cuda/targets/x86_64-linux/lib/libcudnn_ops_train.so.8 
sudo ln -sf /usr/local/cuda/targets/x86_64-linux/lib/libcudnn_cnn_infer.so.8.9.2 /usr/local/cuda/targets/x86_64-linux/lib/libcudnn_cnn_infer.so.8 
sudo ln -sf /usr/local/cuda/targets/x86_64-linux/lib/libcudnn.so.8.6.0 /usr/local/cuda/targets/x86_64-linux/lib/libcudnn.so.8
```

```bash
sudo ldconfig ldconfig -N -v $(sed 's/:/ /' <<< $LD_LIBRARY_PATH) 2>/dev/null | grep libcudnn
```

### 오류 메시지:

```bash
/sbin/ldconfig: /usr/local/cuda/targets/x86_64-linux/lib/libcudnn_ops_train.so.8 is not a symbolic link
/sbin/ldconfig: /usr/local/cuda/targets/x86_64-linux/lib/libcudnn_ops_infer.so.8 is not a symbolic link
/sbin/ldconfig: /usr/local/cuda/targets/x86_64-linux/lib/libcudnn_cnn_train.so.8 is not a symbolic link
/sbin/ldconfig: /usr/local/cuda/targets/x86_64-linux/lib/libcudnn_cnn_infer.so.8 is not a symbolic link
/sbin/ldconfig: /usr/local/cuda/targets/x86_64-linux/lib/libcudnn_adv_train.so.8 is not a symbolic link
/sbin/ldconfig: /usr/local/cuda/targets/x86_64-linux/lib/libcudnn_adv_infer.so.8 is not a symbolic link
/sbin/ldconfig: /usr/local/cuda/targets/x86_64-linux/lib/libcudnn.so.8 is not a symbolic link
```

## 6. 테스트

```bash
sudo nvidia-ctk cdi generate --output=/etc/cdi/nvidia.yaml
nvidia-ctk cdi list
nvidia-smi
nvcc -V
```

```bash
sudo podman volume create yacht
sudo podman run --privileged -v /var/run/podman/podman.sock:/var/run/docker.sock  -v yacht:/config -p 8000:8000 --name yacht -d ghcr.io/selfhostedpro/yacht:latest
```

## 참고

- [Nvidia-docker 설치](https://velog.io/@boom109/Nvidia-docker)
    
- [NVIDIA Container Toolkit 설치](https://velog.io/@cjw9105/NVIDIA-Container-Toolkit-%EC%84%A4%EC%B9%98)
    
- [CUDA Toolkit Archive](https://developer.nvidia.com/cuda-toolkit-archive)
    
- [cuDNN 다운로드](https://developer.nvidia.com/rdp/cudnn-download)
    
- [NVIDIA Container Toolkit Install Guide](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html)
    

---